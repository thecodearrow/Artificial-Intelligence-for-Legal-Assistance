{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-IR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reLflvah_CHb",
        "outputId": "1ce5f282-7efa-45de-ed99-b43533e7959b"
      },
      "source": [
        "#Dependencies\n",
        "!pip install transformers\n",
        "!pip install bert-extractive-summarizer\n",
        "\n",
        "!pip install spacy\n",
        "!pip install neuralcoref\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (4.1.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (50.3.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: neuralcoref in /usr/local/lib/python3.6/dist-packages (4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.19.4)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.16.40)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.40 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.19.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.3.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.40->boto3->neuralcoref) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.40->boto3->neuralcoref) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOicHkTqTMDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf92d90-190e-4ed5-b233-21d52258c9bb"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtKR8i2EzEHt",
        "outputId": "4c0e6972-c13e-466f-ee98-566be93c2b73"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers import BertForNextSentencePrediction\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokens=tokenizer.tokenize(case_doc_100)\n",
        "print('Tokenized: ', tokens)\n",
        "\n",
        "encoded=tokenizer.encode(\n",
        "                        case_doc_100,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "print(encoded)\n",
        "print(\"Length encoded\",len(encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized:  ['state', 'of', 'uttar', 'pradesh', 'and', 'others', 'v', 'des', '##h', 'raj', 'supreme', 'court', 'of', 'india', '23', 'november', '2006', 'appeal', '(', 'civil', ')', '56', '##7', '##4', 'of', '2006', 'the', 'judgment', 'was', 'delivered', 'by', ':', 's', '.', 'b', '.', 'sin', '##ha', ',', 'j', '.', 'leave', 'granted', '.', 'it', 'is', 'also', 'doubtful', 'as', 'to', 'whether', 'the', 'imp', '##ug', '##ned', 'directions', 'could', 'have', 'been', 'issued', 'even', 'at', 'the', 'final', 'hearing', 'of', 'the', 'matter', 'which', 'would', 'amount', 'to', 'creation', 'of', 'super', '##num', '##era', '##ry', 'post', 'in', 'purported', 'compliance', 'of', 'the', 'regular', '##isation', 'rules', '.', 'an', 'appointment', 'which', 'was', 'made', 'throwing', 'all', 'constitutional', 'obligations', 'and', 'statutory', 'rules', 'to', 'winds', 'would', 'render', 'the', 'same', 'illegal', 'whereas', 'irregular', '##ity', 'pre', 'suppose', '##s', 'substantial', 'compliance', 'of', 'the', 'rules', '.']\n",
            "[101, 2110, 1997, 14940, 7970, 1998, 2500, 1058, 4078, 2232, 11948, 4259, 2457, 1997, 2634, 2603, 2281, 2294, 5574, 1006, 2942, 1007, 5179, 2581, 2549, 1997, 2294, 1996, 8689, 2001, 5359, 2011, 1024, 1055, 1012, 1038, 1012, 8254, 3270, 1010, 1046, 1012, 2681, 4379, 1012, 2009, 2003, 2036, 21888, 2004, 2000, 3251, 1996, 17727, 15916, 7228, 7826, 2071, 2031, 2042, 3843, 2130, 2012, 1996, 2345, 4994, 1997, 1996, 3043, 2029, 2052, 3815, 2000, 4325, 1997, 3565, 19172, 6906, 2854, 2695, 1999, 27023, 12646, 1997, 1996, 3180, 6648, 3513, 1012, 2019, 6098, 2029, 2001, 2081, 6886, 2035, 6543, 14422, 1998, 15201, 3513, 2000, 7266, 2052, 17552, 1996, 2168, 6206, 6168, 12052, 3012, 3653, 6814, 2015, 6937, 12646, 1997, 1996, 3513, 1012, 102]\n",
            "Length encoded 121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5EpnkL5XmZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960f5318-f73f-4e2a-d39f-361f533090b3"
      },
      "source": [
        "#Ref— https://medium.com/runwayml/whats-my-line-next-sentence-prediction-in-runway-ad76cbf28c86\n",
        "#Note this is just to explain the intuition behind going for BERT \n",
        "#The embeddings for doc/ query was actually collected using bert-extractive-summarizer\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForNextSentencePrediction\n",
        "import torch\n",
        "\n",
        "\n",
        "def summarize_text(text):\n",
        "  model = Summarizer()\n",
        "  summarised = model(text, min_length=100,num_sentences=2)\n",
        "\n",
        "  return summarised\n",
        "def sequence_score(inputs):\n",
        "\tmodel = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
        "\ttokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\tline1 = inputs['query']\n",
        "\tdocuments = inputs['docs']\n",
        "\tloss_scores = []\n",
        "\tfor i,doc in enumerate(documents):\n",
        "\t\tcombined = inputs['query'] + ' ' + doc\n",
        "\t\tinput_tokens = tokenizer.encode(combined, add_special_tokens=True)\n",
        "\t\tinput_ids = torch.tensor(input_tokens).unsqueeze(0)\n",
        "\t\toutputs = model(input_ids)\n",
        "\t\tsequence_loss = outputs[0][0][0]     # we take the first bit output\n",
        "\t\tsequence_loss = float(sequence_loss.cpu().detach().numpy())\n",
        "\t\tloss_scores.append(sequence_loss)\n",
        "\t\tprint(\"Doc \"+str(i)+\"=>\", sequence_loss)\n",
        "\treturn loss_scores\n",
        "\n",
        "\n",
        "\n",
        "query=\"fights between landlords and farmers\"\n",
        "doc11=\"legal disputes\"\n",
        "doc22=\"massive killings\"\n",
        "inputs={'query':query,'docs':docs}\n",
        "sequence_score(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Doc 0=> 5.153006553649902\n",
            "Doc 1=> 5.55983829498291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.153006553649902, 5.55983829498291]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDzFwRtYKyZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39787afa-f5f6-4df0-f068-88994128080d"
      },
      "source": [
        "#Text Summarisation of Case Docs \n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "from collections import defaultdict\n",
        "from summarizer import Summarizer\n",
        "\n",
        "model = Summarizer()\n",
        "\n",
        "\n",
        "doc0=\"\"\"\n",
        "Masud Khan v State Of Uttar Pradesh\n",
        "Supreme Court of India\n",
        "\n",
        "26 September 1973\n",
        "Writ Petition No. 117 of 1973\n",
        "The Judgment was delivered by : A. Alagiriswami, J.\n",
        "1.  Petitioner Masud Khan prays for his release on the ground that he, an Indian citizen has been illegally arrested and confined to, jail under Paragraph 5 of the Foreigners (Internment) Order, 1962. He had come to India from Pakistan on the basis of a Pakistani passport dated 137-1954and Indian visa dated 9-4-1956. In his application for visa he had stated that he had migrated to Pakistan in 1948 and was in Government service in Pakistan in P.W.D. as a Darogha and had given his permanent address as Hyderabad (Sind).\n",
        "2.  If these statements were correct the petitioner would clearly be a Pakistani national. When this fact was brought out in the counter affidavit filled on behalf of the respondent, the petitioner filed a further affidavit stating that he was appointed as a Police Constable in Hasanganj Police Station, District Fatehpur, U.P. in February 1947 and continued as a Police Constable till the middle of 1950 when he was dismissed from service, and that he went to Pakistan in the year 1951.In the reply affidavit filed on behalf of the respondent it is stated that one Md. Masood Khan son of Zahoor Khan was enrolled as Police Constable on 16-9-1947 and he was discharged from service on 20-5-1949. It is fairly clear that this information culled from the English Order Book from 1-101947 to 27-12-1951 refers to the petitioner. While, therefore, it is established that the petitioner did not go to Pakistan in 1948, it cannot be said that it has been established that the petitioner went to Pakistan only in 1951.When he went to Pakistan is a matter peculiarly within his knowledge and the produced no evidence in support of that statement.\n",
        "3.  Considering the frequent change of ground which the petitioner has resorted to, a mere statement from him cannot be accepted as true. Nor can we accept his contention that it is for the respondent to establish that lie did not go to Pakistan in 1951 but that he went on some other date. The petitioner has also alleged that he was married in U.P. on 25th December, 1949.Even assuming that this statement is correct; the petitioner cannot establish that he is a citizen of India unless lie succeeds in establishing that he was in India on 26-1-1950. If he bad been in India on 26-1-1950 but had gone to Pakistan in 1951 it would be for the Central Government to decide whether he is a Pakistani national or an Indian citizen even though he may have come to India on a Pakistani passport in 1956. That question does not arise here.\n",
        "4.  We are not prepared to assume that the petitioner should be deemed to have been present in India on 26-1-1950, as was urged on behalf of the petitioner. There is no room for any such presumption. Under s-9 of the Foreigners Act whenever a question arises whether a person is or is not a foreigner the onus of proving that he is not a foreigner lies upon him. The burden is therefore, upon the petitioner to establish that be is a citizen of India in the manner claimed by him and therefore be is not a foreigner. This burden not having been discharged by the petitioner it should be held that he is a foreigner and his claim that he is an Indian citizen cannot be dealt with under the Foreigners (Internment) Order, 1962 must be rejected.\n",
        "5.  It appears, however, that in 1960 he had been prosecuted before the Sub-Divisional Magistrate, Fatehpur under s. 14 of the Foreigner--, Act and was acquitted on the ground that he was not a foreigner. It was therefore contended that the question whether the petitioner is -a foreigner or not is a matter of issue estoppels. The decision that he was not a foreigner seems to have been based on the decision of the Allahabad High Court in Mohd. Hanif Khan v. State (AIR 1960 All. 434). 1959 Indlaw ALL 154It was held there that a Pakistani national who entered into India before the amendment to the Foreigners Act in 1957, when he could not be considered to be a foreigner, could not be so held because of that amendment. That decision was that of a learned Single Judge. On the point at issue he differed from an earlier decision of a learned Single Judge of the same Court in Ali Sher v. The State (AIR 1960 All. 431). 1959 Indlaw ALL 153But he decided that case before him on a different point and did not think it necessary to refer the case before him to a Bench for considering which of the two decisions was correct on the question regarding the nationality of a person who came to India on a Pakistani passport before 1957. There are thus two conflicting decisions of the same court on the same point and the Magistrate who decided the petitioner's case followed one of them.\n",
        "6.  But that apart, this matter could bedecided on another point.. The question of issue-estoppels has been considered by this Court in Pritam Singh v. State, of Punjab (AIR1956 SC 415), 1955 Indlaw SC 111 Manipur Administration v. Thokchom, Bira Singh (1964 7 SCR 123) 1964 Indlaw SC 413 and Piara Singh S. State of Punjab. Issue-estoppels arises only if the earlier as well as the subsequent proceedings were criminal prosecutions. In the present case while the earlier one was a criminal prosecution the present is merely an action taken, under the Foreigners (Internment) Order for the purpose of deporting the petitioner out of India.\n",
        "7.  It is nota criminal prosecution. The principle of issue estoppels is simply this : that where an issue of fact has been tried by a competent court on a former occasion and a finding has been reached in favored an accused, such a finding would constitute an estoppels or res judicator against the prosecution not as a bar to the trial and conviction of the accused for a different or distinct offence but as precluding the reception of evidence to disturb that finding of fact when the accused is tried subsequently, even for different offence which might be permitted by law. Pritam Singh's case 1955 Indlaw SC 111 (supra) was based on the decision of the Privy Council in Sambasivam v. Public, Prosecutor, Federation of Malaya (1950 A.C. 458). In that case Lord McDermott speaking for the Board said:\n",
        "\"The effect of a verdict of acquittal pronounced by a competent court on a lawful charge and after a lawful trial is not completely stated by saying that the person acquitted cannot be tried again for the same offence. To that it must be added that the verdict is binding and conclusive in all subsequent proceedings between the parties to the adjudication.\"\n",
        "It should bekept clearly in mind that the proceeding referred to herein is a criminal prosecution. The plea of issue-estoppels not the same as the, plea of double jeopardy or aura foist acquit. In The King v. Wilkes (77 C.L.R.511)\n",
        "Divon, J.\n",
        "8.  Referring to the question of issue estoppel said. view that there is an issue estoppels, if it appears by record of itself or as explained by proper evidence, that the same point was determined in favour of a prisoner in a previous criminal trial which is brought in issue on a second criminal trial of the same prisoners There must be prior proceeding determined against the Crown necessarily involving an issue which again arises in a subsequent proceeding by the Crown against the same prisoner. The allegation of the Crown in the subsequent proceeding must itself be inconsistent with the acquittal of the prisoner in the previous proceeding. But if such a condition of affairs arises I see no reason why the ordinary rules of issue-estoppels should not apply Issue-estoppels concerned with the judicial establishment of a proposition of law or fact between parties. It depends upon well-known doctrines which control the reiteration of issues which are settled by prior litigation.\"\n",
        "\"The emphasis here again would be seen to be on the determination of, criminal liability. In Marz v. The Queen (96 C.L.R. 62) the High Court of Australia said \"The Crown is as much precluded by an estoppels by judgment in criminal proceedings as is a subject in civil proceedings The laws which gives effect to issue estoppels is not concerned with the correctness or incorrectness of the finding which amounts to an estoppels, still less with the process of reasoning by which the finding was reached. in fact It is enough that an issue or issues have been distinctly raised or found. Once that is done, then, so long as the finding stands, if there be any subsequent litigation between the same parties, no allegations legally inconsistent with the finding, may be made by one of them against the other.\"\n",
        "Here again it is to be remembered that the principle applies to two criminal proceedings and the proceeding with which we are now concerned is not a criminal proceeding. We therefore hold that there is no substance in this contention.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "query=\"\"\"The appellant on February 9, 1961 was appointed as an Officer in Grade III in the respondent Bank ( for short 'the Bank'). He was promoted on April 1, 1968 to the Grade officer in the Foreign Exchange Department in the Head Office of the Bank. Sometime in 1964, MCH Society ( for short 'the Society') was formed of which the appellant was one of the chief promoters and thereafter its Secretary. The object of the Society was to construct residential premises for the employees of the Bank and its other members. It appears that the complaint was received in respect of the affairs of the Society relating to misappropriation of the funds of the Society and consequently, in exercise of the powers under Section S of Act A1, the Registrar on April 23, 1969 instituted an inquiry thereof. P1 was appointed the Registrar's nominee who on October 4, 1969; submitted the report holding the appellant and two other office bearers of the Society negligent in dealing with the funds of the Society causing a loss to the tune of Rs. 3,59,000/-. The Registrar on October 21, 1969, passed an order appointing an officer under Section S of A1 to assess the loss caused to the Society. However, the Government by its order dated November 29, 1969 annulled the Registrar's order dated April 23, 1969 and October 21, 1969 and directed a fresh inquiry into the affairs of the Society. On December 17, 1969, the Bank issued show cause notice to the appellant to explain within fifteen days his alleged negligent conduct in dealing with the affairs of the Society as revealed in the report dated 4th October, 1969. In the meantime, P2 came to be appointed by the Registrar vide his order dated 26th July, 1969, to make inquiries under Section S of A1. Petitioner by his reply dated 18/22th January, 1970 submitted his explanation and also challenged the legality of the inquiry and the findings recorded therein. On 5th March, 1970, P3, treasurer of the Society and an employee of the Bank criminal complaints in the Court of Addl. Chief Presidency Magistrate  alleging that the appellant and two other office bearers of the society had dishonestly misappropriated a sum of Rs. 51,000/ and Rs. 80,000/- respectively which was entrusted to the appellant in his capacity as Promoter and Secretary of the Society and thereby committed criminal breach of trust. The Magistrate framed the charges against the appellant. The Bank having regard to the serious misconduct of the appellant involving moral turpitude vide its order dated 3rd November, 1970 suspended the appellant pending trial. The appellant protested this action of the Bank complaining that he was not given an opportunity of hearing before passing the order of suspension. In the meantime, P2, the authorized officer appointed by the Registrar vide his order dated 9th October, 1971 held the appellant liable to pay Rs. 2,36,000/- to the Society in addition to the amount of Rs. 2,03,000/- for which he (the appellant) and two other office bearers of the Society were held jointly liable. The Bank in view of this finding, vide its order dated 29th November, 1971 terminated the services of the appellant with effect from 1st December, 1971 along with notice pay. The appellant protested against the Action of the Bank and on 3rd December, 1971 filed detailed representation against the order of termination. The Bank replied to the appellant's representation and justified its action. The appellant on 28th December, 1971 submitted his reply to the Bank stating, inter alia, that the termination of his services was not simplicitor and was in violation of the principles of natural justice; that no opportunity of hearing was given to him; that the termination order attached stigma. The appellant aggrieved by the findings and order made by P2 appealed before Tribunal. In the meantime, the criminal proceedings ended in conviction vide order dated 27th March, 1972 passed by the Addl. Chief Metropolitan Magistrate. The appellant challenged the order of conviction and sentence in the High Court  and during the pendency of the said appeal, the Tribunal vide its order dated April 12, 1973 dismissed the appellant's appeal but reduced the liability by Rs. 72,000/-. On November 12, 1973, the High Court allowed the criminal appeal and acquitted the appellant. The High Court, however, in its order observed that since the services of the appellant were terminated in view of the criminal proceedings and since the appellant has been acquitted, representation, if a any, by the appellant to the Bank for reinstatement may be considered sympathetically. Taking clue from the observations made by the High Court, the appellant filed three representations, the last being dated 3rd May, 1975 requesting the Bank to revoke the order of termination and be reinstated. The Bank vide its communication dated May 21, 1975 refused to reinstate the appellant. The appellant, therefore, on July 23, 1975 filed the writ petition in the High Court for quashing the orders dated 29th November 1971, 27th December, 1971 and 21st May, 1975 passed by the Bank. The learned Single Judge of the High Court by his judgment and order dated December 6/7, 1979 granted desired relief to the appellant. The Bank aggrieved by the judgment and order passed by the learned Single Judge preferred an appeal under Clause 15 of the Letters Patent. The appeal was heard by the Division Bench. The Division Bench of the High Court did not agree with the judgment passed by the learned Single Judge and consequently by its judgment and order dated April 16 1985 allowed the appeal and dismissed the writ petition the ground of laches and also on merits. It is this judgment and order of the High Court which is impugned in this appeal.\"\"\"\n",
        "\n",
        "case_doc0_summ=model(query,num_sentences=3)\n",
        "print(\"Summary of doc—\",case_doc0_summ)\n",
        "print()\n",
        "print(\"Length of original doc—\", len(doc0))\n",
        "print(\"Length of original doc—\", len(case_doc0_summ))\n",
        "bert_embedding=model.run_embeddings(doc0, num_sentences=20,aggregate='mean')\n",
        "print(\"The embedding is—\",bert_embedding)\n",
        "print(bert_embedding)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary of doc— The appellant on February 9, 1961 was appointed as an Officer in Grade III in the respondent Bank ( for short 'the Bank'). It appears that the complaint was received in respect of the affairs of the Society relating to misappropriation of the funds of the Society and consequently, in exercise of the powers under Section S of Act A1, the Registrar on April 23, 1969 instituted an inquiry thereof. On November 12, 1973, the High Court allowed the criminal appeal and acquitted the appellant. Taking clue from the observations made by the High Court, the appellant filed three representations, the last being dated 3rd May, 1975 requesting the Bank to revoke the order of termination and be reinstated.\n",
            "\n",
            "Length of original doc— 8870\n",
            "Length of original doc— 701\n",
            "The embedding is— [-1.1194632  -0.47189993 -0.11958978 ...  0.10920823  0.31443277\n",
            " -0.3085639 ]\n",
            "[-1.1194632  -0.47189993 -0.11958978 ...  0.10920823  0.31443277\n",
            " -0.3085639 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5rBM4z-NySc"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "#Case docs\n",
        "\"\"\"\n",
        "uploaded = files.upload()\n",
        "df= pd.read_csv(io.BytesIO(uploaded['case_docs.csv']))\n",
        "print(df)\n",
        "\"\"\"\n",
        "uploaded = files.upload()\n",
        "df= pd.read_csv(io.BytesIO(uploaded['case_docs_200.csv']))\n",
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXwvwxLBOOz1"
      },
      "source": [
        "#Query doc\n",
        "uploaded2 = files.upload()\n",
        "qdf= pd.read_csv(io.BytesIO(uploaded2['query.csv']))\n",
        "print(qdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3N-NwTUOUA0"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "nltk.download('punkt')  \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    #also whitespace\n",
        "    translator = str.maketrans('', '', string.punctuation) \n",
        "    return text.translate(translator)\n",
        "\n",
        "def remove_stop_words_and_lemmatize(sentence):\n",
        "  sentence=remove_punctuation(sentence)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  word_tokens = word_tokenize(sentence) \n",
        "  word_tokens=[word.lower() for word in word_tokens]\n",
        "  filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized_sentence=[lemmatizer.lemmatize(w) for w in filtered_sentence]  \n",
        "  return lemmatized_sentence\n",
        "  \n",
        "\n",
        "def give_me_synonyms(word):\n",
        "  synonyms=set()\n",
        "  for synset in wordnet.synsets(word):\n",
        "    for lemma in synset.lemmas():\n",
        "      syn=lemma.name()\n",
        "      synonyms.add(syn)\n",
        "  return list(synonyms)\n",
        "\n",
        "def expand_query(query,limit=500):\n",
        "  query_processed=remove_stop_words_and_lemmatize(query)\n",
        "  query_new=[]\n",
        "  count=0\n",
        "  for word_current in query_processed:\n",
        "    query_new.append(word_current) #make sure the old word is there\n",
        "    query_synonyms=give_me_synonyms(word_current)\n",
        "    for word_new in query_synonyms:\n",
        "      query_new.append(word_new)\n",
        "      if(count>limit):\n",
        "        return query_new\n",
        "  \n",
        "  return query_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ9-P5viOqpP"
      },
      "source": [
        "#Store text summarized case docs, lemmatized case doc and embeddings !\n",
        "import numpy as np\n",
        "new_document=[]\n",
        "embeddings=[]\n",
        "for i, row in df.iterrows():\n",
        "  print(\"processing doc\",i+1)\n",
        "  doc=row['original']\n",
        "  lem_doc=row['lemmatized']\n",
        "  #lem_doc=remove_stop_words_and_lemmatize(doc)\n",
        "  #lem_doc=\" \".join(lem_doc)\n",
        "  #doc_type1=model(doc,min_length=50)\n",
        "  #doc_type2=model(doc,num_sentences=1)\n",
        "  embedding=model.run_embeddings(doc,aggregate='mean')\n",
        "  embedding=np.reshape(embedding,(1,1024))\n",
        "  embeddings.append(embedding)\n",
        "  #new_document.append({\"original\":doc,\"lemmatized\":lem_doc,\"summarized_256\":doc_256}) #use a wrapper around the numpy array imp!\n",
        "\n",
        "#download lemmatized and summarized text\n",
        "\"\"\"\n",
        "result_display=pd.DataFrame(new_document)\n",
        "print(result_display)\n",
        "result_display.to_csv('case_docs_200.csv') \n",
        "files.download('case_docs_200.csv')\n",
        "\"\"\"\n",
        "\n",
        "#download embeddings\n",
        "embeddings=np.array(embeddings)\n",
        "print(embeddings.shape)\n",
        "np.save('embeddings.npy', embeddings)\n",
        "files.download('embeddings.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57A0brXzPHjt"
      },
      "source": [
        "#Get Query Embeddings\n",
        "\n",
        "queries_list=[]\n",
        "query_embeddings=[]\n",
        "for i,row in qdf.iterrows():\n",
        "  query=row[\"Query\"]\n",
        "  lem_query=\" \".join(remove_stop_words_and_lemmatize(query))\n",
        "  embedding=model.run_embeddings(query,aggregate='median')\n",
        "  embedding=np.reshape(embedding,(1,1024))\n",
        "  query_embeddings.append(embedding)\n",
        "  queries_list.append({\"index\":row[\"Index\"],\"query\":row['Query'],\"lemmatized\":lem_query,\"relevant\":rel_df.loc[i,\"relevant\"]})\n",
        "\n",
        "\n",
        "query_display=pd.DataFrame(queries_list)\n",
        "#print(query_display[\"embedding\"])\n",
        "query_display.to_csv('embedded_queries.csv') \n",
        "files.download('embedded_queries.csv')\n",
        "\n",
        "#download embeddings\n",
        "query_embeddings=np.array(query_embeddings)\n",
        "print(query_embeddings.shape)\n",
        "np.save('query_embeddings.npy', query_embeddings)\n",
        "files.download('query_embeddings.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}